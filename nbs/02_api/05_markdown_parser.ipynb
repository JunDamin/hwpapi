{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markdown Parser\n",
    "\n",
    "마크다운으로 입력된 내용을 한글 형식에 맞춰서 작성이 되도록 하려고 합니다.\n",
    "\n",
    "전체 표준을 다 반영하긴 어렵겠지만, 아래와 같이 일부 항목을 반영하고자 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 구조 토큰의 종류 정의\n",
    "STRUCTURE_TOKENS = [\n",
    "    ('HEADER1', r'(^|\\n)# (.*?)(\\n|$)'),\n",
    "    ('HEADER2', r'(^|\\n)## (.*?)(\\n|$)'),\n",
    "    ('HEADER3', r'(^|\\n)### (.*?)(\\n|$)'),\n",
    "    ('HEADER4', r'(^|\\n)#### (.*?)(\\n|$)'),\n",
    "    ('HEADER5', r'(^|\\n)##### (.*?)(\\n|$)'),\n",
    "    ('HEADER6', r'(^|\\n)###### (.*?)(\\n|$)'),\n",
    "    ('LIST_ITEM', r'(^|\\n)( *)(-|\\+|\\*) (.*?)(\\n|$)'),\n",
    "    ('ORDERED_LIST_ITEM', r'(^|\\n)( *)(\\d+)\\. (.*?)(\\n|$)'),\n",
    "    ('TABLE_SEPARATOR', r'(^|\\n)\\|[-\\s|]*?\\|(\\n|$)'),\n",
    "    ('TABLE_ROW', r'(^|\\n)\\|.*?\\|(\\n|$)'),\n",
    "    ('NEWLINE', r'\\n'),\n",
    "    ('TEXT', r'[^\\n]+')\n",
    "]\n",
    "\n",
    "# 구조 토크나이저 함수 구현\n",
    "def tokenize_structure(text):\n",
    "    tokens = []\n",
    "    while text:\n",
    "        for token_type, pattern in STRUCTURE_TOKENS:\n",
    "            match = re.match(pattern, text)\n",
    "            if match:\n",
    "                if token_type in ['LIST_ITEM', 'ORDERED_LIST_ITEM']:\n",
    "                    indent = len(match.group(2))\n",
    "                    tokens.append((token_type, indent, match.group(4).strip()))\n",
    "                else:\n",
    "                    tokens.append((token_type, match.group().strip()))\n",
    "                text = text[match.end():]\n",
    "                break\n",
    "        else:\n",
    "            # 매칭되는 패턴이 없는 경우 텍스트에서 첫 글자를 잘라냄\n",
    "            text = text[1:]\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서식 토큰의 종류 정의\n",
    "FORMATTING_TOKENS = [\n",
    "    ('BOLD', r'\\*\\*(.*?)\\*\\*'),\n",
    "    ('ITALIC', r'\\*(.*?)\\*'),\n",
    "    ('TEXT', r'[^#\\*\\n]+')\n",
    "]\n",
    "\n",
    "# 서식 토크나이저 함수 구현\n",
    "def tokenize_formatting(text):\n",
    "    tokens = []\n",
    "    while text:\n",
    "        for token_type, pattern in FORMATTING_TOKENS:\n",
    "            match = re.match(pattern, text)\n",
    "            if match:\n",
    "                tokens.append((token_type, match.group().strip()))\n",
    "                text = text[match.end():]\n",
    "                break\n",
    "        else:\n",
    "            # 매칭되는 패턴이 없는 경우 텍스트에서 첫 글자를 잘라냄\n",
    "            text = text[1:]\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('HEADER1', '# Hello World')\n",
      "('NEWLINE', '')\n",
      "('TEXT', 'This is a **bold** text and this is *italic* text.')\n",
      "('NEWLINE', '')\n",
      "('LIST_ITEM', 0, 'Item 1')\n",
      "('LIST_ITEM', 2, 'Subitem 1.1 with **bold** text')\n",
      "('LIST_ITEM', 2, 'Subitem 1.2 with *italic* text')\n",
      "('LIST_ITEM', 4, 'Subsubitem 1.2.1 with **bold** and *italic* text')\n",
      "('LIST_ITEM', 0, 'Item 2')\n",
      "('ORDERED_LIST_ITEM', 0, 'First item with **bold** text')\n",
      "('ORDERED_LIST_ITEM', 0, 'Second item with *italic* text')\n",
      "('ORDERED_LIST_ITEM', 2, 'Subitem 2.1 with **bold** and *italic* text')\n",
      "('ORDERED_LIST_ITEM', 2, 'Subitem 2.2')\n",
      "('TABLE_ROW', '| Header1 | Header2 |')\n",
      "('TABLE_SEPARATOR', '| ------- | ------- |')\n",
      "('TABLE_ROW', '| Data1 with **bold** | Data2 with *italic* |')\n",
      "('TABLE_ROW', '| Data3 | Data4 with **bold** and *italic* |')\n"
     ]
    }
   ],
   "source": [
    "# 테스트용 마크다운 텍스트\n",
    "markdown_text = \"\"\"\n",
    "# Hello World\n",
    "\n",
    "This is a **bold** text and this is *italic* text.\n",
    "\n",
    "- Item 1\n",
    "  - Subitem 1.1 with **bold** text\n",
    "  - Subitem 1.2 with *italic* text\n",
    "    - Subsubitem 1.2.1 with **bold** and *italic* text\n",
    "- Item 2\n",
    "\n",
    "1. First item with **bold** text\n",
    "2. Second item with *italic* text\n",
    "  1. Subitem 2.1 with **bold** and *italic* text\n",
    "  2. Subitem 2.2\n",
    "\n",
    "| Header1 | Header2 |\n",
    "| ------- | ------- |\n",
    "| Data1 with **bold** | Data2 with *italic* |\n",
    "| Data3 | Data4 with **bold** and *italic* |\n",
    "\"\"\"\n",
    "\n",
    "# 토큰화 및 파싱 실행\n",
    "structure_tokens = tokenize_structure(markdown_text)\n",
    "\n",
    "for token in structure_tokens:\n",
    "  print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
